!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.dense_design_matrix.DenseDesignMatrix {
        X: !pkl: 'X_train.pkl',
        y: !pkl: 'y_train.pkl',
        y_labels: 10,
    },

    model: !obj:pylearn2.models.mlp.MLP {
        layers : [
            !obj:pylearn2.models.mlp.Sigmoid {
                layer_name: 'h0',
                dim: 200,
                sparse_init: 15,
                # Rather than using weight decay, we constrain the norms of the weight vectors
                # max_col_norm: 2.
            },
            !obj:pylearn2.models.mlp.Sigmoid {
                layer_name: 'h1',
                dim: 200,
                sparse_init: 15,
                # Rather than using weight decay, we constrain the norms of the weight vectors
                # max_col_norm: 2.
            },
            !obj:pylearn2.models.mlp.Softmax {
                layer_name: 'y',
                n_classes: 10,
                irange: .0,
                init_bias_target_marginals: *train
            }
        ],
        nvis: 400,
    },

    # We train using batch gradient descent
    algorithm: !obj:pylearn2.training_algorithms.bgd.BGD {
        #learning_rate: 1e-1,
        batch_size: 250,

        #learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
        #    init_momentum: 0.5,
        #},

        cost: !obj:pylearn2.costs.cost.SumOfCosts {
            costs: [
                !obj:pylearn2.costs.cost.MethodCost {
                    method: 'cost_from_X'
                },
                !obj:pylearn2.costs.mlp.WeightDecay {
                    coeffs: [5e-4, 5e-4, 5e-4]
                }
            ]
        },

        # We monitor how well we're doing during training on a validation set
        monitoring_dataset: {
            'train' : *train,
            'valid' : !obj:pylearn2.datasets.dense_design_matrix.DenseDesignMatrix {
                X: !pkl: 'X_test.pkl',
                y: !pkl: 'y_test.pkl',
                y_labels: 10,
            },
        },

        # We stop after 5 epochs
        termination_criterion: !obj:pylearn2.termination_criteria.EpochCounter {
            max_epochs: 40
        },
    },
    save_freq : 10
    # We save the model whenever we improve on the validation set classification error
    #extensions: [
    #    !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
    #         channel_name: 'valid_y_misclass',
    #         save_path: "mlp_best.pkl"
    #    },
    #]
}
